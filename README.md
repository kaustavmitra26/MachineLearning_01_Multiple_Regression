Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable).
The Formula for Multiple Linear Regression is:

y 
i
​	 =β 
0
​	 +β 
1
​	 x 
i1
​	 +β 
2
​	 x 
i2
​	 +...+β 
p
​	 x 
ip
​	 +ϵ

where, for i=n observations:
y 
i
​	 =dependent variable
x 
i
​	 =expanatory variables
β 
0
​	 =y-intercept (constant term)
β 
p
​	 =slope coefficients for each explanatory variable
ϵ=the model’s error term (also known as the residuals)
​	

The Difference Between Linear and Multiple Regression
Linear (OLS) regression compares the response of a dependent variable given a change in some explanatory variable. However, it is rare that a dependent variable is explained by only one variable. In this case, an analyst uses multiple regression, which attempts to explain a dependent variable using more than one independent variable. Multiple regressions can be linear and nonlinear.

Multiple regressions are based on the assumption that there is a linear relationship between both the dependent and independent variables. It also assumes no major correlation between the independent variables.
